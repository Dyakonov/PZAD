# ПЗАД: "Прикладные задачи анализа данных"

* курс на факультете ВМК, МГУ имени М.В. Ломоносова
* читается по 2 занятия в неделю, есть лекции и семинары
* для магистров: 517 группа (каф. математических методов прогнозирования) + спецкурс
* лектор: [Александр Дьяконов](https://dyakonov.org/ag/)


# Для желающих послушать как спецкурс

Необходимо записаться 

Нужная информация будет в рассылке + необходимо следить за обновлением информации здесь.

По почте писать лектору бесполезно.

# Особенности 2021 года

Скорее всего формат курса будет "самостоятельное изучение лекций" (все лекции выложены в [**ютубе**](https://youtube.com/playlist?list=PLaRUeIuewv8CMFox0oEjlyePUhUmo-x0h)). Но будет много сопровождающих заданий. Задания отличны от заданий прошлого года! Будут постоянные проекты по темам лекций.

# Материалы 2020 года

* видеоматериалы 2020 года: [**канал курса на ютубе**](https://youtube.com/playlist?list=PLaRUeIuewv8CMFox0oEjlyePUhUmo-x0h)
* задания выложены в закрытом классруме
* обсуждения по курсу в закрытом телеграм-канале
* слайды представлены ниже

### Слайды лекций 2020 года

| тема | программа |
| :-- | :-- |
| [**Введение**](./2020/PZAD2020_000intro_05n.pdf) 11.09.2020 | Вводная лекция|
| [**Оценки среднего, вероятности и плотности; весовые схемы**](./2020/PZAD2020_011probweights_07n.pdf) 11.09.2020 | Понятие «среднее»: разные формализации, полюсы/минусы, практика. Среднее арифметическое. Медиана. многомерная медиана.Многомерная медиана как результат итерационного процесса. Среднее как решение оптимизационной задачи. Оценка минимального контраста. Среднее для номинальных признаков? Среднее по А.Н.Колмогорову. Тропическое среднее. Оценка вероятности как среднего: сглаживание Лапласа и весовые схемы. case: некорректности при вычислении вероятности.|
| [**CASE: Прогнозирование визитов покупателей супермаркетов и сумм их покупок**](./2020/PZAD2020_012caseclients_04n.pdf) 18.09.2020 | Постановка задачи. Предположения метода. Оценки вероятности / весовые схемы. Оценки плотности / весовые схемы. «Состыковка» алгоритмов.|
| [**CASE: задача о пробках**](./2020/PZAD2020_013traffic_02n.pdf ) 18.09.2020 | Постановка задачи. Двухмерное усреднение. Особенности данных. Специальное усреднение.|
| [**Искусство визуализации (часть 1 - историческая)**](./2020/PZAD2020_021vishistory_04.pdf) 18.09.2020 | Обоснование визуализации: квартет Энскомба. Цели визуализации. История анализа данных и инфографики: Джозеф Пристли, Уильям Плейфэр, Шарль Жозеф Минар, Флоренс Найтингейл, Уильям Дюбуа, Джон Сноу. Примеры плохих визуализаций: 3D-графика, нелинейные сравнения, диаграммы-пироги (pie). Максимизация «Data-Ink». Визуальные обманы. Визуализация для профессионала. Правило минимализма. Правило использования разнообразных средств. Рекомендации по выбору масштаба графиков и шкалы, пояснительного текста, цвета и стиля изображений. Табличные данные.|
| **Игра "Что изображено?"** слайды не выкладываются 25.09.2020 | |
| [**Искусство визуализации (часть 2 - одномерный анализ)**](./2020/PZAD2020_022visunivar_04.pdf) 25.09.2020 | Описательные статистики: среднее, характерные элементы, разброс значений, абсолютные вариации, относительные вариации, моменты, cтандартизованные моменты. Пример визуализаций описательных статистик. Исследование частей выборки (фолдов), визуализация важностей признаков, первичные действия при анализе признака. Визуализация отдельных признаков: диаграммы, гистограммы, плотности распределения, выбор числа бинов, трансформации признаков. Визуализация категориальных признаков: гистограммы, диаграммы-пироги и области, уточнение природы признака.|
| [**Искусство визуализации (часть 3 - многомерный анализ)**](./2020/PZAD2020_023vismultivar_03.pdf) 02.10.2020 | Визуализация пары признаков: корреляция, зависимость признаков, независимость признаков, типичные значения, выбросы, кластеры. Диаграмма рассеивания. Использования шума для визуализации. Сводные таблицы, треугольные зависимости. Визуализации пары «вещественный признак» – «категориальный». Сравнение с бенчмарком. Визуализация «ответ алгоритма» – «ответ алгоритма». Визуализация «ответ алгоритма» – «признак». Деформации ответов и признаков. Residual plot. Корреляции. 3D-визуализации. Визуализация служебных признаков. Проверка соответствия «train-test». Агрегация.|
| [**Метрики качества. Часть 1. Функции ошибки в задаче регрессии**](./2020/PZAD2020_031err_regression_10n.pdf) 09.10.2020 | Средний модуль отклонения MAE(MAD), средний квадрат отклонения MSE, его производные: RMSE, коэффициент детерминации R2, вероятностное и невероятностное обоснование RMSE, функция Хьюбера, Logcosh, обобщения MAE и RMSE, процентные функции ошибок (SMAPE, MAPE, PMAD), ошибки, основанные на сравнении с бенчмарком (MRAE, REL_MAE, PB), нормированные ошибки (MASE), несимметричные ошибки, ошибки с точностью до порога, использование функций ошибок для генерации признаков.|
| [**Метрики качества. Часть 2. Чёткая бинарная классификации**](./2020/PZAD2020_032err_classification_20n.pdf) 09.10.2020 | Матрица ошибок / несоответствий «Сonfusion Matrix», точность (Accuracy, MCE), ошибки 1 и 2 рода, полнота (Recall, TPR, Sensitivity), специфичность (Specificity , TNR), точность (Precision),обратная точность (Inverse Precision), FPR(False Positive Rate), F1-мера, F-мера, Каппа Коэна (Cohen's Kappa), , Коэффициент Мэттьюса (MCC), Сбалансированная точность (Balanced Accuracy), сравнение функционалов на модельной задаче.|
| [**Метрики качества.  Часть 3: скоринговые функции и кривые в машинном обучении**](./2020/PZAD2020_033err_scoreandcurves_13n.pdf) 23.10.2020 | Задачи с ответом в виде оценки принадлежности, скоринговые ошибки: логистическая функция ошибки Log Loss, MSE, Misclassification Loss, Exploss; Площадь под ROC-кривой, AUROC, GINI (кривая Лоренца), кривая «полнота-точность», Gain Curve (Chart), Lift Curve (Chart), Kolomogorov Smirnov chart, The Gains Table.|
| [**Метрики качества. Часть 4: многоклассовые задачи, ранжирование, кластеризация**](./2020/PZAD2020_034err_multirankcluster_03.pdf) 23.10.2020 | Weighted kappa, Многоклассовая задача «Multi-label»: Hamming Loss, Log Loss (cross-entropy), Mean Probability Rate, MSE, MAE, многоклассовый AUCROC, точность, полнота, F1-мера, сбалансированная точность «Balanced accuracy». Усреднения: микро-подход, макро-подход, макро-подход с весами, по объектам. *Оценка результатов поиска/рекомендаций: Precision at n, Average Precision at n, Mean Average Precision, Concordant – Discordant ratio, Mean Reciprocal Rank (MRR), Cumulative Gain at n, Discounted Cumulative Gain at n, Normalized DCG, Ранговые корреляции, Expected reciprocal rank (ERR). Редакторское расстояние.* Задача с «неклассическим целевым вектором»: Коэффициент Жаккара (Jaccard), коэффициент Шимкевича-Симпсона (Szymkiewicz, Simpson), коэффициент Браун-Бланке (Braun-Blanquet), коэффициент Сёренсена (Sörensen), коэффициент Кульчинского (Kulczinsky), коэффициент Отиаи (Ochiai). *Оценка результатов кластеризации: внешняя оценка (External evaluation): взаимная информация (mutual information - MI), скорректированная взаимная информация (Adjusted mutual information), V-мера, Adjusted Rand index, общий подход (Rand index, Fowlkes-Mallows index - FMI). Внутренняя оценка (Internal evaluation): Davies–Bouldin index, Dunn index, Silhouette, Calinski-Harabasz Index (Variance Ratio Criterion).*                                                     курсивом - пропущенное|
| [**Метрики качества: задачи и кейсы**](./2020/PZAD2020_035minfunc_05nold.pdf) 30.10.2020 | Как настраиваться на конкретные функции. Идеология РП. Критерий расщепления для AUC. CASE: Вычисление матожидания ошибки. Задачи с интервальными признаками. Обоснование деформации логарифмом. Градиентный спуск. Задачи для решения.|
| [**Подготовка данных**](./2020/PZAD2020_041datapreprocessing_04.pdf) 06.11.2020 | Фундаментальные свойства данных. Виды данных. Предобработка данных. Очистка данных (Data Cleaning): аномалии/выбросы, пропуски, шум, некорректные значения. Сокращение данных (Data Reduction): сэмплирование, сокращение размерности, отбор признаков, отбор объектов. Трансформация данных (Data Transformation): переименование признаков, объектов, значений признаков, преобразование типов; кодирование значений категориальных переменных; дискретизация; нормализация; сглаживание; создание признаков; агрегирование; обобщение; деформация значений. Интеграция данных.|
| [**Генерация признаков**](./2020/PZAD2020_042featureengineering_07.pdf) 13.11.2020 | Типы числовых признаков. Контекстные признаки. Служебные признаки. Утечка в данных. Странности в данных. Использование EDA для генерации признаков. Вещественные признаки.  Строковые признаки. Временные признаки (характеристики моментов времени, взаимодействие пары признаков, использование для других признаков, использование для генерации признаков, использование для уточнения задачи). Географические (пространственные) признаки: Spatial Variables. (проекции на разные оси, кластеризация, идентификация, привязка, характеристики окрестности, анализ траекторий, деанонимизация данных, использование контекста и исследование странностей, генерация расстояний и использование для других признаков). Обработка категориальных признаков (обнаружение, создание новых, кодирование – по номеру категории Label Encoding, Dummy-кодирование / One-hot-encoding, по значениям вещественного признака, по значениям категориального признака – Count Encoding, Frequency Encoding, По значениям ДРУГОГО категориального признака, Хэш-кодирование, по значению целевого – Target Encoding, экспертное кодирование, вложение категориальных признаков в маломерное пространство – Category Embedding).  Проблема мелких и новых категорий.|
| [**Ансамбли**](./2020/PZAD2020_051ensemble_14n.pdf) 27.11.2020 | Ансамбли алгоритмов: примеры и обоснование (статистическое, вычислительное, функциональное). Повышения разнообразия в ансамбле. Комитеты (голосование) / усреднение. Бэгинг (bootstrap aggregating). OOB-prediction. Кодировки / перекодировки ответов, ECOC (Error-Correcting Output Code). Стекинг (stacking) и блендинг. Бустинг: AdaBoost (алгоритм, вывод формул), Forward stagewise additive modeling (FSAM). «Ручные методы». Однородные ансамбли.|
| [**Анализ социальных / сложных сетей**](./2020/PZAD2020_061SNA_09old.pdf) 04.12.2020 |  Исследование социальных сетей (Social Network Analysis). Примеры соцсетей. Задачи с социальными сетями. Основные понятия теории графов. Понятие сложной сети (Complex network): 1. Степенные законы распределения степеней вершин (Power law degree distribution), правило Парето (Vilfredo Pareto, закон Ципфа (Zipf's Law) 2. Модель «малого мира»: малый диаметр и т.п. («small world»). Большая компонента связности (Giant component). 3. Высокий коэффициент кластеризации (Hight clustering coefficient). 4. Разреженность (Sparcity). 5. Сильные и слабые связи, кластерная структура. Теория связей. Гомофилия. Моделирование графов модель Пола Эрдёша и Альфреда Реньи (Erdös-Renyi). Моделирование графов: Модель Ваттса-Строгаца (Watts–Strogatz). Моделирование графов: Преимущественное присоединение Barábasi-Albert model (1999). Моделирование графов: выбор рёбер (Link Selection Model), Copying Model. Моделирование графов: c помощью кирпичиков (motif – кирпичик). Эволюция графов. Сети с негативными связями.Модель Шеллинга (Schelling’s model).|
| [**Прогнозирование появления ребра в динамическом графе (Link Prediction Problem)**](./2020/PZAD2020_062LPP_07old.pdf) 11.12.2020 |  Признаковые пространства, построенные по графам. Сходство вершин. Важность вершин. Степенная центральность (Degree centrality). Центральность по близости (Closeness centrality). Центральность по путям (Betweenness centrality). Собственная центральность (Eigenvector centrality) . Эксцентриситетная центральность (Eccentricity centrality). Устойчивость понятий. Важность группы (Group Centrality). Прогнозирование появления ребра в динамическом графе (Link Prediction Problem). Расстояние на графе (graph distance). Число соседей (common neighbors). коэффициент предпочтительности (preferential attachment). коэффициент Жаккара. коэффициент Адамик/Адара. SimRank. вероятностные методы. Алгоритм PageRank. HITS=«Hyperlink Induced Topic Search». Соревнование «IJCNN Social Network Challenge».|
| [**Выделение сообществ (Community Detection)**](./2020/PZAD2020_063community_10old.pdf) 11.12.2020 |  Сообщество в графе. Примеры сообществ. Датасет Карате-клуб. Разбиение графа: Kerninghan-Lin Algorithm. Обычная кластеризация с мерой схожести вершин. Edge betweenness (Girvan-Newmann’s method). модулярность. Fast community unfolding: Louvain method / Multilevel. Walktrap. Infomap. спектральная теория графов  использование. Spectral modularity maximization. Тестирование разных методов. Задача: выделение кругов пользователей в эго-подграфах графов социальной сети.|
| [**Случайный лес**](./2020/PZAD2020_052rf_10n.pdf) 18.12.2020 |  Универсальные методы. Случайный лес. Бэггинг. OOB (out of bag). Настройка параметров методов. Области устойчивости. Близости, вычисленные по RF. Extreme Random Trees. Приложения RF: Biological Response. Приложения RF: Реальная задача (Photo). Приложения RF: Калибровка RF. Приложения RF: Задача Search Results Relevance.|
| [**Важность признаков в ансамблях деревьев**](./2020/PZAD2020_044featureimportance_04.pdf) 18.12.2020 |  Проблема формализации важности признаков. Примеры использования важности признаков. Важность по неоднородности (impurity-based importance). Перестановочная важность PFI (Permutation Feature Importance). Эксперименты по оцениванию важности. Boruta (идея). ACE (Artificial Contrasts with Ensembles).|

### дополнительные темы

| тема | программа |
| :-- | :-- |
| **Градиентный бустинг** ??.??.???? | Градиентный бустинг над деревьями. Итерация градиентного бустинга. Наискорейший спуск. Эвристика сокращения – Shrinkage. Стохастический градиентный бустинг. TreeBoost – градиентный бустинг над деревьями. Продвинутые методы оптимизации. Современные реализации градиентного бустинга: XGBoost, LightGBM, CatBoost. Встроенные способы контроля. Параметры градиентного бустинга. Case: Задача скоринга (TKS). Калибровка. Case: предсказание ответов на вопросы.|
| **Рекомендательные системы (Recommender Systems): классические методы** ??.??.???? | Описание и назначение. Цели рекомендательных систем. Виды рекомендаций. Данные для рекомендаций, сбор данных. Объекты рекомендаций. цели бизнеса. Новизна товаров. Разные каналы рекомендаций. Мифы о рекомендательных системах. История исследований в рекомендательных системах. Рекомендации по контенту (content based methods). Коллаборативная фильтрация. GroupLens-алгоритм. Похожесть пользователей и товаров. Алгоритм «YouTube». Рекомендация на основе матричных разложений (SVD, SVD++, timeSVD++). Учёт времени при рекомендациях. Адаптация SVD под социальные связи. One-class recommendation. Факторизационные машины. Факторизационная машина с полями (FFM). Простые методы рекомендаций. Случайные блуждания в RecSys. Функционалы качества. Желаемые свойства рекомендаций. Контекст. Реакция пользователей. Knowledge-based Recommendations. Важность объяснений (explanations). A/B-тесты.|
| **Глубокое обучение в рекомендательных системах** ??.??.???? | Глубокое обучение в рекомендательных системах. Первые опыты – RBM. использование «простых» нейросетей. Deep CF. Deep Semantic Similarity Model (DSSM). Collaborative Metric Learning (CML). DL: пример рекомендаций в YouTube. DL: Автокодировщики. DL: использование CNN. CONTENT2VEC. Анализ сессий. Использование RNN. Иерархические RNN. Вложения (представления). Использование дополнительной информации. Тренды. Тестирование алгоритмов. Разбор кейса: технология LenKor для рекомендации видео. История одного тестирования.|
| **Интерпретация данных и модели** ??.??.???? | *была в 2019 году* |
| **Простые методы решения сложных задач** ??.??.???? | *перенесена в вводный курс?*|
| **Отбор признаков** ??.??.???? | *больше тема для основного ML*|
| **Детектирование аномалий** ??.??.???? | *больше тема для основного ML*|
| **Спектральная теория графов** ??.??.???? | *теория для SNA*|
| **Теория нечётких множеств** ??.??.???? | *теория для некоторых разделов*|
| **Анализ выживаемости** ??.??.???? | *тема, которая не обозревалась в других разделах*|
| **Бизнес-аспекты в ПЗАД** ??.??.???? | *не читалась*|
